# NLP

Natural Language Processing (NLP) Projects
This repository contains implementations of various Natural Language Processing techniques and models, covering preprocessing, tagging, sentiment analysis, vectorization, and topic modeling.

### 📂 Contents
1. Text Preprocessing

2. Text Tagging

3. Sentiment Analysis

4. Text Vectorization

5. Text Modeling

## 1. 🧹 Text Preprocessing
Preprocessing is the first step in NLP to clean and standardize raw text for better model performance.

### Steps Implemented:
1. Lowercasing – Convert all text to lowercase to maintain uniformity.

2. Stopwords Removal – Remove common words (e.g., "the", "and") that don’t add significant meaning.

3. Regular Expressions – Clean unwanted patterns like punctuation, numbers, or special characters.

4. Tokenization – Split text into individual words or tokens.

5. Stemming – Reduce words to their root form (e.g., running → run).

6. Lemmatization – Reduce words to their base form considering grammar (e.g., better → good).

7. N-Grams – Create combinations of words (e.g., bigrams, trigrams) to capture context.

## 2. 🏷️ Text Tagging
Assigning linguistic information to text.

1. POS (Part-of-Speech) Tagging – Identify grammatical roles (noun, verb, adjective, etc.).

2. NER (Named Entity Recognition) – Identify and classify named entities (persons, organizations, locations, etc.).

## 3. 😊 Sentiment Analysis
Analyzing the emotional tone of text.

1. Rule-based Approach – Using predefined lexicons (e.g., VADER) to calculate sentiment scores.

2. Pretrained Models – Using ML/DL models to predict sentiment from text.

## 4. 🧮 Text Vectorization
Converting text into numerical form for machine learning models.

1. Bag of Words (BoW) – Represent text as word frequency counts.

2. TF-IDF (Term Frequency – Inverse Document Frequency) – Weight words based on their importance in the document and corpus.

## 5. 📊 Text Modeling
Finding hidden topics in text using dimensionality reduction and probabilistic models.

1. LSA (Latent Semantic Analysis) – Reduce dimensions using SVD to uncover hidden topics.

2. LDA (Latent Dirichlet Allocation) – Probabilistic topic modeling to find word-topic distributions.
