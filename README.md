# NLP

Natural Language Processing (NLP) Projects
This repository contains implementations of various Natural Language Processing techniques and models, covering preprocessing, tagging, sentiment analysis, vectorization, and topic modeling.

### ğŸ“‚ Contents
1. Text Preprocessing

2. Text Tagging

3. Sentiment Analysis

4. Text Vectorization

5. Text Modeling

## 1. ğŸ§¹ Text Preprocessing
Preprocessing is the first step in NLP to clean and standardize raw text for better model performance.

### Steps Implemented:
1. Lowercasing â€“ Convert all text to lowercase to maintain uniformity.

2. Stopwords Removal â€“ Remove common words (e.g., "the", "and") that donâ€™t add significant meaning.

3. Regular Expressions â€“ Clean unwanted patterns like punctuation, numbers, or special characters.

4. Tokenization â€“ Split text into individual words or tokens.

5. Stemming â€“ Reduce words to their root form (e.g., running â†’ run).

6. Lemmatization â€“ Reduce words to their base form considering grammar (e.g., better â†’ good).

7. N-Grams â€“ Create combinations of words (e.g., bigrams, trigrams) to capture context.

## 2. ğŸ·ï¸ Text Tagging
Assigning linguistic information to text.

1. POS (Part-of-Speech) Tagging â€“ Identify grammatical roles (noun, verb, adjective, etc.).

2. NER (Named Entity Recognition) â€“ Identify and classify named entities (persons, organizations, locations, etc.).

## 3. ğŸ˜Š Sentiment Analysis
Analyzing the emotional tone of text.

1. Rule-based Approach â€“ Using predefined lexicons (e.g., VADER) to calculate sentiment scores.

2. Pretrained Models â€“ Using ML/DL models to predict sentiment from text.

## 4. ğŸ§® Text Vectorization
Converting text into numerical form for machine learning models.

1. Bag of Words (BoW) â€“ Represent text as word frequency counts.

2. TF-IDF (Term Frequency â€“ Inverse Document Frequency) â€“ Weight words based on their importance in the document and corpus.

## 5. ğŸ“Š Text Modeling
Finding hidden topics in text using dimensionality reduction and probabilistic models.

1. LSA (Latent Semantic Analysis) â€“ Reduce dimensions using SVD to uncover hidden topics.

2. LDA (Latent Dirichlet Allocation) â€“ Probabilistic topic modeling to find word-topic distributions.
