{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WueHa3S9D3yW"
      },
      "source": [
        "# Lemmatization\n",
        "\n",
        "Where stemming removes the last few characters of a word, lemmatization stems the word to a more meaningful base form and ensures it does not lose it's meaning. Lemmatization works more intelligently, referencing a pre-defined dictionary containing the context of words and uses this when diminishing the word to the base form."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpusGHcKD3yZ"
      },
      "outputs": [],
      "source": [
        "connect_tokens = ['connecting', 'connected', 'connectivity', 'connect', 'connects']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJqcnAotD3ya"
      },
      "outputs": [],
      "source": [
        "learn_tokens = ['learned', 'learning', 'learn', 'learns', 'learner', 'learners']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pndB0xNcD3yb"
      },
      "outputs": [],
      "source": [
        "likes_tokens = ['likes', 'better', 'worse']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfFvpA5-D3yb"
      },
      "source": [
        "## Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJtBRqXXD3yb"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikWNZEFqD3yc"
      },
      "outputs": [],
      "source": [
        "# create stemmer\n",
        "ps = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsfbqP4ED3yc",
        "outputId": "091c976b-3c9d-4677-a1b1-4ee9d2ce35c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "connecting  :  connect\n",
            "connected  :  connect\n",
            "connectivity  :  connect\n",
            "connect  :  connect\n",
            "connects  :  connect\n"
          ]
        }
      ],
      "source": [
        "for t in connect_tokens:\n",
        "    print(t, \" : \", ps.stem(t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gM9Mxv6eD3yd",
        "outputId": "a71061d7-640e-4c67-cb7e-9b1825d48a31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learned  :  learn\n",
            "learning  :  learn\n",
            "learn  :  learn\n",
            "learns  :  learn\n",
            "learner  :  learner\n",
            "learners  :  learner\n"
          ]
        }
      ],
      "source": [
        "for t in learn_tokens:\n",
        "    print(t, \" : \", ps.stem(t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbhKwOPjD3yd",
        "outputId": "da37e086-cac6-4521-ed52-29190782dd46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "likes  :  like\n",
            "better  :  better\n",
            "worse  :  wors\n"
          ]
        }
      ],
      "source": [
        "for t in likes_tokens:\n",
        "    print(t, \" : \", ps.stem(t))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCpMksM4D3yd"
      },
      "source": [
        "## Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVXkZKOiD3ye",
        "outputId": "0016c3ed-d1c6-42f4-c52c-ed6483ae4b3f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\lnewb\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXcLDmd9D3ye"
      },
      "outputs": [],
      "source": [
        "# create lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Diza6gQUD3ye",
        "outputId": "cc2c48ec-3181-4e4f-e1e8-68d272a0d085"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "connecting  :  connecting\n",
            "connected  :  connected\n",
            "connectivity  :  connectivity\n",
            "connect  :  connect\n",
            "connects  :  connects\n"
          ]
        }
      ],
      "source": [
        "for t in connect_tokens:\n",
        "    print(t, \" : \", lemmatizer.lemmatize(t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ch4oIuMCD3ye",
        "outputId": "315c7e51-ded3-4c98-96fb-fe43e3074aa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learned  :  learned\n",
            "learning  :  learning\n",
            "learn  :  learn\n",
            "learns  :  learns\n",
            "learner  :  learner\n",
            "learners  :  learner\n"
          ]
        }
      ],
      "source": [
        "for t in learn_tokens:\n",
        "    print(t, \" : \", lemmatizer.lemmatize(t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8a6OvIUKD3yf",
        "outputId": "9c869fbf-b438-4360-e8da-5f011e5de128"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "likes  :  like\n",
            "better  :  better\n",
            "worse  :  worse\n"
          ]
        }
      ],
      "source": [
        "for t in likes_tokens:\n",
        "    print(t, \" : \", lemmatizer.lemmatize(t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeTrg7ekD3yg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
